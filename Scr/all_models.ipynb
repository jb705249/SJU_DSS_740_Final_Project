{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Classification Model to Predict Loan Approval </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Import packages/classes and load the data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, validation_curve, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline \n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create functions to use for the data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm(y_pred, y_test, model=str, tuned=False, smote=False):\n",
    "    \"\"\"\n",
    "    Creates the confusion matrix for the model and outputs the evaluation metrics\n",
    "\n",
    "    Inputs:\n",
    "    1. y_pred   :      Model predictions from test set\n",
    "    2. y_test   :      Test set\n",
    "    3.title     :      Name of the model -- Logistic Regression, SVM, Decision Tree\n",
    "    4.tuned     :      Set to yes if the model was tuned. Default False\n",
    "    5.smote     :      Set to yes if smote was applied to the data. Default False \n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Annotations for squares\n",
    "group_names = ['True Neg (TN)', 'False Pos (FP)', 'False Neg (FN)', 'True Pos (TP)']\n",
    "group_counts = [f'{value}' for value in cm.flatten()]\n",
    "labels = [f'{name}\\n{count}' for name, count in zip(group_names, group_counts)]\n",
    "labels = np.array(labels).reshape(2, 2)\n",
    "\n",
    "# Plot\n",
    "sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', cbar=False, linewidths=0.5, linecolor='gray')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for Logistic Regression\\n')\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['No (0)', 'Yes (1)'])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['No (0)', 'Yes (1)'], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>change</th>\n",
       "      <th>rationale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>Removed 3 row(s) where age &gt; 125</td>\n",
       "      <td>Oldest verified human lived to be 122; values above 125 are likely errors or outliers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loan_status</td>\n",
       "      <td>Dropped loan_status column</td>\n",
       "      <td>Target variable for classification; not needed in cleaned dataset.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>person_income</td>\n",
       "      <td>Capped person_income at $3,000,000 and applied log1p transformation</td>\n",
       "      <td>Handled extreme right skew and outliers in income distribution; log1p applied to normalize values and removed person_income for modeling.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loan_amnt</td>\n",
       "      <td>Applied log1p transformation to loan_amount</td>\n",
       "      <td>Handled extreme right skew and outliers in loan amount distribution; log1p applied to normalize values.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>person_emp_exp</td>\n",
       "      <td>Removed 5 row(s) where person_emp_exp &gt; 70</td>\n",
       "      <td>Unrealistic employment experience; values above 70 years are likely errors or outliers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>person_education</td>\n",
       "      <td>Combined Master and Doctorate categories into one group -- Graduate</td>\n",
       "      <td>Doctorate had the lowest frequency out of all the categories which could impact analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>person_home_ownership</td>\n",
       "      <td>Combined RENT and OTHER into Non-Homeowner category and MORTGAGE and OWN into Homeowner category</td>\n",
       "      <td>RENT and MORTGAGE had high frequencies while OWN and OTHER had low frequencies which could impact analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['person_gender', 'loan_intent', 'previous_loan_defaults_on_file', 'person_education_new', 'person_home_ownership_new']</td>\n",
       "      <td>Applied one-hot encoding (drop_first=True)</td>\n",
       "      <td>Converted categorical variables into binary indicators for model compatibility.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>loan_status</td>\n",
       "      <td>Readded loan_status column</td>\n",
       "      <td>Target variable for classification; readded after cleaning and preprocessing.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    column  \\\n",
       "0                                                                                                                      age   \n",
       "1                                                                                                              loan_status   \n",
       "2                                                                                                            person_income   \n",
       "3                                                                                                                loan_amnt   \n",
       "4                                                                                                           person_emp_exp   \n",
       "5                                                                                                         person_education   \n",
       "6                                                                                                    person_home_ownership   \n",
       "7  ['person_gender', 'loan_intent', 'previous_loan_defaults_on_file', 'person_education_new', 'person_home_ownership_new']   \n",
       "8                                                                                                              loan_status   \n",
       "\n",
       "                                                                                             change  \\\n",
       "0                                                                  Removed 3 row(s) where age > 125   \n",
       "1                                                                        Dropped loan_status column   \n",
       "2                               Capped person_income at $3,000,000 and applied log1p transformation   \n",
       "3                                                       Applied log1p transformation to loan_amount   \n",
       "4                                                        Removed 5 row(s) where person_emp_exp > 70   \n",
       "5                               Combined Master and Doctorate categories into one group -- Graduate   \n",
       "6  Combined RENT and OTHER into Non-Homeowner category and MORTGAGE and OWN into Homeowner category   \n",
       "7                                                        Applied one-hot encoding (drop_first=True)   \n",
       "8                                                                        Readded loan_status column   \n",
       "\n",
       "                                                                                                                                   rationale  \n",
       "0                                                     Oldest verified human lived to be 122; values above 125 are likely errors or outliers.  \n",
       "1                                                                         Target variable for classification; not needed in cleaned dataset.  \n",
       "2  Handled extreme right skew and outliers in income distribution; log1p applied to normalize values and removed person_income for modeling.  \n",
       "3                                    Handled extreme right skew and outliers in loan amount distribution; log1p applied to normalize values.  \n",
       "4                                                    Unrealistic employment experience; values above 70 years are likely errors or outliers.  \n",
       "5                                                   Doctorate had the lowest frequency out of all the categories which could impact analysis  \n",
       "6                                 RENT and MORTGAGE had high frequencies while OWN and OTHER had low frequencies which could impact analysis  \n",
       "7                                                            Converted categorical variables into binary indicators for model compatibility.  \n",
       "8                                                              Target variable for classification; readded after cleaning and preprocessing.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import change_summary\n",
    "changelog = pd.read_csv('../Changelogs/change_summary.csv').to_dict(orient='records')\n",
    "\n",
    "# Change summary intialization and check\n",
    "change_summary = pd.DataFrame(changelog)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(change_summary)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_emp_exp</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>log_income</th>\n",
       "      <th>log_loan_amt</th>\n",
       "      <th>person_gender_male</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "      <th>previous_loan_defaults_on_file_Yes</th>\n",
       "      <th>person_education_new_Bachelor</th>\n",
       "      <th>person_education_new_Graduate</th>\n",
       "      <th>person_education_new_High School</th>\n",
       "      <th>person_home_ownership_new_Non-Homeowner</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>16.02</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3</td>\n",
       "      <td>561</td>\n",
       "      <td>11.183713</td>\n",
       "      <td>10.463132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>504</td>\n",
       "      <td>9.415971</td>\n",
       "      <td>6.908755</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>12.87</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3</td>\n",
       "      <td>635</td>\n",
       "      <td>9.428592</td>\n",
       "      <td>8.612685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>15.23</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2</td>\n",
       "      <td>675</td>\n",
       "      <td>11.286702</td>\n",
       "      <td>10.463132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>14.27</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4</td>\n",
       "      <td>586</td>\n",
       "      <td>11.099469</td>\n",
       "      <td>10.463132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_emp_exp  loan_int_rate  loan_percent_income  \\\n",
       "0          22               0          16.02                 0.49   \n",
       "1          21               0          11.14                 0.08   \n",
       "2          25               3          12.87                 0.44   \n",
       "3          23               0          15.23                 0.44   \n",
       "4          24               1          14.27                 0.53   \n",
       "\n",
       "   cb_person_cred_hist_length  credit_score  log_income  log_loan_amt  \\\n",
       "0                           3           561   11.183713     10.463132   \n",
       "1                           2           504    9.415971      6.908755   \n",
       "2                           3           635    9.428592      8.612685   \n",
       "3                           2           675   11.286702     10.463132   \n",
       "4                           4           586   11.099469     10.463132   \n",
       "\n",
       "   person_gender_male  loan_intent_EDUCATION  loan_intent_HOMEIMPROVEMENT  \\\n",
       "0                   0                      0                            0   \n",
       "1                   0                      1                            0   \n",
       "2                   0                      0                            0   \n",
       "3                   0                      0                            0   \n",
       "4                   1                      0                            0   \n",
       "\n",
       "   loan_intent_MEDICAL  loan_intent_PERSONAL  loan_intent_VENTURE  \\\n",
       "0                    0                     1                    0   \n",
       "1                    0                     0                    0   \n",
       "2                    1                     0                    0   \n",
       "3                    1                     0                    0   \n",
       "4                    1                     0                    0   \n",
       "\n",
       "   previous_loan_defaults_on_file_Yes  person_education_new_Bachelor  \\\n",
       "0                                   0                              0   \n",
       "1                                   1                              0   \n",
       "2                                   0                              0   \n",
       "3                                   0                              1   \n",
       "4                                   0                              0   \n",
       "\n",
       "   person_education_new_Graduate  person_education_new_High School  \\\n",
       "0                              1                                 0   \n",
       "1                              0                                 1   \n",
       "2                              0                                 1   \n",
       "3                              0                                 0   \n",
       "4                              1                                 0   \n",
       "\n",
       "   person_home_ownership_new_Non-Homeowner  loan_status  \n",
       "0                                        1            1  \n",
       "1                                        0            0  \n",
       "2                                        0            1  \n",
       "3                                        1            1  \n",
       "4                                        1            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned data from CSV\n",
    "df = pd.read_csv(\"../Data/cleaned_loan_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Prep </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target variable\n",
    "X = df.drop(columns=['loan_status'])\n",
    "y = df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (31494, 19)\n",
      "X_test: (13498, 19)\n"
     ]
    }
   ],
   "source": [
    "#Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True, stratify=y)\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set:\n",
      "loan_status\n",
      "0    0.777799\n",
      "1    0.222201\n",
      "Name: proportion, dtype: float64\n",
      "Class distribution in test set:\n",
      "loan_status\n",
      "0    0.777819\n",
      "1    0.222181\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Check for class imbalance\n",
    "print(f\"Class distribution in training set:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Class distribution in test set:\\n{y_test.value_counts(normalize=True)}\")\n",
    "\n",
    "# Changelog addition\n",
    "changelog.append({\n",
    "    'column': 'numerical_columns',\n",
    "    'change': 'Applied MinMaxScaler to training data; transformed test data using same scaler.',\n",
    "    'rationale': 'Avoided data leakage by fitting scaler only on training data. Ensures proper model generalization and adheres to machine learning best practices.'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Apply Smote to handle the imbalance data <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE for handling class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote_train, y_smote_train = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Check the class distribution after SMOTE\n",
    "X_smote_test = X_test_scaled\n",
    "y_smote_test = y_test\n",
    "\n",
    "# Changelog entry for SMOTE\n",
    "changelog.append({\n",
    "    'column': 'subscribe_to_term_deposit',\n",
    "    'change': f'Resampled training set with SMOTE (train shape now: {X_smote_train.shape}, test shape: {X_test.shape})',\n",
    "    'rationale': 'Used SMOTE to correct class imbalance in training data for better model performance.'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Build the Models </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Model 1: Logistic Regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lrBase = LogisticRegression(max_iter=1000)\n",
    "lrBase.fit(X_train_scaled, y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
