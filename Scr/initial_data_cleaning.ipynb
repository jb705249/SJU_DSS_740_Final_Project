{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b07a8b77",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "## 4/20/2025\n",
    "\n",
    "- Team Members\n",
    "    - Brittney Bedrossian\n",
    "    - Breenda Shah\n",
    "    - Jeb Besecker\n",
    "    - Kevin Dennin\n",
    "    - Kohry Long\n",
    "\n",
    "### This serves as an initial exploration and data pre processing module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5725673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hello world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a594763a",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eee1933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as mno\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import graphviz\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b76cd",
   "metadata": {},
   "source": [
    "# Changelog Intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f26136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize changelog\n",
    "changelog = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fdccab",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9c83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../Data/loan_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6867061c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bac569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intial Stats of numerical variables\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7db7c8",
   "metadata": {},
   "source": [
    "**Initial observations of the numerical variables** - The dataset contains 45,000 records and provides insights into individuals' demographics, income, employment experience, and loan-related details. The average age of individuals is approximately 27.76 years, with a minimum of 20 and a maximum of 144 years, suggesting a likely data outlier at the upper end. Similarly, the person_income variable has a mean of about $80,319, but a maximum value of over $7.2 million indicates the presence of extreme outliers. Employment experience (person_emp_exp) averages around 5.41 years, though the maximum value of 125 years is likely unrealistic and could also be an error. Loan amounts range from $500 to $35,000, with a mean of approximately $9,583, while interest rates vary from 5.42% to 20%, averaging around 11%. The loan_percent_income, which represents the loan amount as a proportion of income, has a mean of 0.14. Credit history length and credit scores also show considerable variation, with the average credit score being 632 and ranging from 390 to 850. Lastly, the loan_status variable indicates that around 22% of individuals in the dataset received loan approval. Overall, the data shows strong variability, and several features may require cleaning or normalization due to the presence of clear outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209167e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intial Stats of categorical variables\n",
    "df.describe(include = object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c244253d",
   "metadata": {},
   "source": [
    "**Initial observation of categorical variables** - the majority of the population is male, accounting for 24,841 entries. Education levels are diverse, with five unique categories, and the most common qualification is a Bachelorâ€™s degree, held by 13,399 individuals. When it comes to housing status, renting is the most frequent form of home ownership, with 23,443 individuals reporting it. The dataset also records loan intentions, with six distinct purposes, of which education-related loans are the most common, making up 9,153 entries. Lastly, the variable indicating whether individuals had previous loan defaults shows an almost even split, with 22,858 people having a history of loan defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore MissingNo\n",
    "mno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c26166",
   "metadata": {},
   "source": [
    "# Data Exploration and Categorical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Categorical columns:\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250be539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis of categorical variables\n",
    "for col in categorical_columns + ['loan_status']:\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    df[col].value_counts(normalize=True).plot(kind='bar')\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64397c6b",
   "metadata": {},
   "source": [
    "# Notes on Categorical Analysis:\n",
    "Firstly, there are no spelling errors present in the dataset. Secondly, given that the \"Own\" and \"Other\" categories constitute a small proportion of the person_home_ownership variable, it may be appropriate to consolidate them into a single \"Others\" category for more effective analysis. Lastly, the overall distribution of the remaining categorical variables appears well-balanced. However, an exception is observed in the person_education variable, where the \"Doctorate\" group represents a notably small subset of the population - consider dropping this all together. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ee668",
   "metadata": {},
   "source": [
    "# Numerical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec6c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis of numerical variables\n",
    "numerical_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"Numerical columns:\", numerical_columns)\n",
    "for col in numerical_columns:\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0add95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for skewness in each of the numerical variables\n",
    "numericalColumns = df.select_dtypes(include=[ 'int64'])\n",
    "numericalColumns[:10]              \n",
    "\n",
    "#Checking for skewness in the numerical columns.\n",
    "skewness = df[numericalColumns.columns].skew()\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e58a6",
   "metadata": {},
   "source": [
    "# Notes on Numerical variables\n",
    "The skewness results for the numerical variables indicate that several distributions are significantly non-normal, with a strong tendency toward right skewness. Notably, person_income shows an extreme right skew (skewness = 34.14), suggesting the presence of a few individuals with very high incomes that distort the overall distribution. Similarly, person_age and person_emp_exp both exhibit strong right skewness (2.55 and 2.59, respectively), likely influenced by outliers such as individuals with unusually high age or employment experience values as mentioned earlier in summary stats. The loan_amnt and cb_person_cred_hist_length variables also display moderate right skewness, indicating that most applicants request lower loan amounts and have relatively short credit histories. In contrast, credit_score shows a moderate left skew (-0.61), suggesting a concentration of higher credit scores with fewer individuals having poor credit. Lastly, the loan_status variable is moderately right-skewed (1.34), reflecting an imbalance in loan approvals versus rejections, which may require attention during classification tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df.select_dtypes(include=['float64', 'int64']).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347ddf4",
   "metadata": {},
   "source": [
    "# Notes on Correlation Matrix\n",
    "Strong positive correlations: person_age and person_emp_exp (0.95): Older individuals tend to have more work experience, person_age and cb_person_cred_hist_length (0.86): Older applicants generally have longer credit histories, and person_emp_exp and cb_person_cred_hist_length (0.82): More experienced individuals also tend to have longer credit histories.\n",
    "\n",
    "Moderate correlations:loan_amnt and loan_percent_income (0.59): Larger loan amounts typically make up a higher percentage of a personâ€™s income, loan_status and loan_percent_income (0.38): Applicants with a higher loan-to-income ratio are more likely to be rejected, and loan_status and loan_int_rate (0.33): Higher interest rates are moderately associated with loan rejection.\n",
    "\n",
    "Weak or negligible correlations:loan_status has weak correlation with most features, including person_age, person_income, person_emp_exp, and credit_score and person_income shows very little correlation with other variables, except a slight negative correlation with loan_percent_income (-0.23)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d509ebe6",
   "metadata": {},
   "source": [
    "# Identifying Numerical Variable Multicolinearity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749080b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['person_income', 'person_emp_exp', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length','credit_score']\n",
    "\n",
    "# Subset the numerical columns\n",
    "X = df[num_cols].copy()\n",
    "\n",
    "# Add constant term for VIF calculation (intercept)\n",
    "X_const = add_constant(X)\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_const.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_const.values, i) for i in range(X_const.shape[1])]\n",
    "\n",
    "# Drop constant term (intercept) from results for clarity\n",
    "vif_data = vif_data[vif_data[\"Feature\"] != \"const\"]\n",
    "\n",
    "print(vif_data)\n",
    "\n",
    "#Pair plot of numerical columns\n",
    "numerical_vars = ['person_income', 'person_emp_exp', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length','credit_score']\n",
    "sns.pairplot(df[numerical_vars])\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3006c5e",
   "metadata": {},
   "source": [
    "**Notes on Multicolinearity of Numerical variables**\n",
    "The Variance Inflation Factor (VIF) analysis indicates that there is no significant multicollinearity among the selected numerical features in the dataset. All VIF values fall well below the common threshold of 5, suggesting that none of the variables are excessively correlated with one another. Specifically, variables such as person_income, loan_int_rate, and credit_score exhibit very low VIF values, confirming their independence from the other predictors. While person_emp_exp and cb_person_cred_hist_length show moderately higher VIFs around 3, these values are still within acceptable limits and do not pose a concern. Overall, the dataset's numerical features are suitable for use  without the risk of multicollinearity distorting the results. Additionally, the par plot between the numerical columns further suggest no significant relationship amongst the columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff6ded",
   "metadata": {},
   "source": [
    "# Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5609a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy original df to df_cleaned\n",
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unrealistic ages\n",
    "original_row_count = df_cleaned.shape[0]\n",
    "df_cleaned = df_cleaned[df_cleaned['person_age'] <= 125]\n",
    "removed_count = original_row_count - df_cleaned.shape[0]\n",
    "\n",
    "\n",
    "changelog.append({\n",
    "    'column': 'age',\n",
    "    'change': f'Removed {removed_count} row(s) where age > 125',\n",
    "    'rationale': 'Oldest verified human lived to be 122; values above 125 are likely errors or outliers.',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop loan_status column\n",
    "df_cleaned.drop(columns=['loan_status'], inplace=True)\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "numerical_columns = df_cleaned.select_dtypes(include=[np.number]).columns.tolist()\n",
    "changelog.append({\n",
    "    'column': 'loan_status',\n",
    "    'change': 'Dropped loan_status column',\n",
    "    'rationale': 'Target variable for classification; not needed in cleaned dataset.',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc76ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap outliers before log-transform\n",
    "df_cleaned['person_income'] = np.where(df_cleaned['person_income'] > 3_000_000, 3_000_000, df_cleaned['person_income'])\n",
    "\n",
    "\n",
    "# Show numerical columns after capping\n",
    "print(\"Numerical columns after capping:\", numerical_columns)\n",
    "\n",
    "\n",
    "# Apply log1p to preserve 0s and small values\n",
    "df_cleaned['log_income'] = np.log1p(df_cleaned['person_income'])\n",
    "changelog.append({\n",
    "    'column': 'person_income',\n",
    "    'change': 'Capped person_income at $3,000,000 and applied log1p transformation',\n",
    "    'rationale': 'Handled extreme right skew and outliers in income distribution; log1p applied to normalize values and removed person_income for modeling.',\n",
    "})\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(df_cleaned['person_income'], bins=50, kde=True)\n",
    "plt.title(\"Income Before Log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(df_cleaned['log_income'], bins=50, kde=True)\n",
    "plt.title(\"Income After Log\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0610e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop person_income after log-transform\n",
    "df_cleaned.drop(columns=['person_income'], inplace=True)\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "numerical_columns = df_cleaned.select_dtypes(include=[np.number]).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log1p to preserve 0s and small values\n",
    "df_cleaned['log_loan_amt'] = np.log1p(df_cleaned['loan_amnt'])\n",
    "changelog.append({\n",
    "    'column': 'loan_amnt',\n",
    "    'change': 'Applied log1p transformation to loan_amount',\n",
    "    'rationale': 'Handled extreme right skew and outliers in loan amount distribution; log1p applied to normalize values.',\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(df_cleaned['loan_amnt'], bins=50, kde=True)\n",
    "plt.title(\"Loan Before Log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(df_cleaned['log_loan_amt'], bins=50, kde=True)\n",
    "plt.title(\"Loan After Log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop loan_amnt after log-transform\n",
    "df_cleaned.drop(columns=['loan_amnt'], inplace=True)\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "numerical_columns = df_cleaned.select_dtypes(include=[np.number]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2149806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unrealistic person_emp_exp values\n",
    "original_row_count = df_cleaned.shape[0]\n",
    "df_cleaned = df_cleaned[df_cleaned['person_emp_exp'] <= 70]\n",
    "removed_count = original_row_count - df_cleaned.shape[0]\n",
    "changelog.append({\n",
    "    'column': 'person_emp_exp',\n",
    "    'change': f'Removed {removed_count} row(s) where person_emp_exp > 70',\n",
    "    'rationale': 'Unrealistic employment experience; values above 70 years are likely errors or outliers.',\n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b57d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cleaned data\n",
    "df_cleaned.info()\n",
    "df_cleaned.describe()\n",
    "\n",
    "# Plot boxplot for cleaned data\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=df_cleaned[numerical_columns])\n",
    "plt.title('Boxplot of Numerical Features After Cleaning')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a20602",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_columns:\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(df_cleaned[col], kde=True)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab78b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change summary intialization and check\n",
    "change_summary = pd.DataFrame(changelog)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(change_summary)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e36e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cleaned data\n",
    "df_cleaned.info()\n",
    "df_cleaned.describe()\n",
    "\n",
    "# Plot boxplot for cleaned data\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=df_cleaned[numerical_columns])\n",
    "plt.title('Boxplot of Numerical Features After Cleaning')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e4160",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d61153",
   "metadata": {},
   "source": [
    "<h5> Â Regroup the Person Education </h5>\n",
    "Since *Master* and *Doctorate* degrees are both Graduate degrees, we can combine those two categories into one and rename as *Graduate*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c577ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new mappings\n",
    "grad_edu = {'Master': 'Graduate',\n",
    "            'Doctorate': 'Graduate'\n",
    "}\n",
    "\n",
    "#Create new field with the updated values\n",
    "df_cleaned['person_education_new'] = df['person_education'].replace(grad_edu)\n",
    "\n",
    "#View the new distribution for education\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "df_cleaned['person_education_new'].value_counts().plot(kind='bar')\n",
    "plt.title(f\"Distribution of Education\")\n",
    "plt.show()\n",
    "\n",
    "#Drop the original field\n",
    "df_cleaned.drop('person_education', axis=1, inplace=True)\n",
    "\n",
    "#Update the change log\n",
    "changelog.append({\n",
    "    'column': 'person_education',\n",
    "    'change': 'Combined Master and Doctorate categories into one group -- Graduate',\n",
    "    'rationale': 'Doctorate had the lowest frequency out of all the categories which could impact analysis',\n",
    "})\n",
    "\n",
    "#Create dataframe to hold the subset of data\n",
    "other_home_ownership = df[df['person_home_ownership'] == 'OTHER']\n",
    "#Find the number of records that fall into this subset\n",
    "print(\"Number of records: \", len(other_home_ownership))\n",
    "\n",
    "other_home_ownership.describe(include='all')\n",
    "\n",
    "\n",
    "#Look at the distribution for age\n",
    "sns.histplot(other_home_ownership['person_age'], bins=10)\n",
    "\n",
    "#Look at the distribution for loan amount\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "other_home_ownership['loan_status'].value_counts().plot(kind='bar')\n",
    "plt.title(f\"Distribution of Loan Status\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b0082",
   "metadata": {},
   "source": [
    "Within this subset of data, there is a difference in classes such that these records should remain in the dataset and the low frequency of the category should be handled so that it doesn't impact the analysis of the variable.\n",
    "\n",
    "Since the *Rent* and *Mortgage* categories have high frequencies and *Own* and *Other* have lower frequencies, we can combine them into two groups *Homeowner* and *Non-Homeowner*. *Rent* and *Other* would fall under *Non-Homeowner** and *Mortgage* and *Own* would fall until *Homeowner*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping for new categories\n",
    "ownership = {'RENT': 'Non-Homeowner',\n",
    "             'OTHER': 'Non-Homeowner',\n",
    "             'MORTGAGE': 'Homeowner',\n",
    "             'OWN': 'Homeowner'\n",
    "}\n",
    "\n",
    "#Create new field with the updated values\n",
    "df_cleaned['person_home_ownership_new'] = df['person_home_ownership'].replace(ownership)\n",
    "\n",
    "#View the new distribution\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "df_cleaned['person_home_ownership_new'].value_counts().plot(kind='bar')\n",
    "plt.title(f\"Distribution of Home Ownership\")\n",
    "plt.show()\n",
    "\n",
    "#Drop the original field\n",
    "df_cleaned.drop('person_home_ownership', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d453f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the change log\n",
    "changelog.append({\n",
    "    'column': 'person_home_ownership',\n",
    "    'change': 'Combined RENT and OTHER into Non-Homeowner category and MORTGAGE and OWN into Homeowner category',\n",
    "    'rationale': 'RENT and MORTGAGE had high frequencies while OWN and OTHER had low frequencies which could impact analysis',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1a47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reilitialize categorical columns\n",
    "categorical_columns = df_cleaned.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Categorical columns:\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5287a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoding to existing categorical_columns\n",
    "df_cleaned = pd.get_dummies(df_cleaned, columns=categorical_columns, drop_first=True, dtype=int)\n",
    "\n",
    "# Review structure of df_cleaned after encoding\n",
    "df_cleaned.info()\n",
    "\n",
    "# Add to changelog\n",
    "changelog.append({\n",
    "    'column': categorical_columns,\n",
    "    'change': 'Applied one-hot encoding (drop_first=True)',\n",
    "    'rationale': 'Converted categorical variables into binary indicators for model compatibility.',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dabbbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readd target variable\n",
    "df_cleaned['loan_status'] = df['loan_status']\n",
    "\n",
    "# Changelog for readding target variable\n",
    "changelog.append({\n",
    "    'column': 'loan_status',\n",
    "    'change': 'Readded loan_status column',\n",
    "    'rationale': 'Target variable for classification; readded after cleaning and preprocessing.',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change summary intialization and check\n",
    "change_summary = pd.DataFrame(changelog)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(change_summary)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add5945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Change Summary to CSV\n",
    "change_summary.to_csv(\"../Changelogs/change_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f487b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned data\n",
    "df_cleaned.to_csv(\"../Data/cleaned_loan_data.csv\", index=False)\n",
    "print(\"Cleaned data exported to cleaned_loan_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
